---
title: "HW 5"
output: github_document
---

```{r}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


Load key packages

```{r}
library(tidyverse)
library(broom)
library(purrr)
set.seed(1000)
```

## Problem 1

Writing a function that for a fixed group size randomly draws “birthdays” for each person, checks whether there are duplicate birthdays in the group, and returns TRUE or FALSE based on the result.

```{r}
bday_sim = function(n) {
  
  bdays = sample(1:365, size = n, replace = TRUE)
  
  duplicate = length(unique(bdays)) < n #check for any duplicates, and FALSE if <n
  
  return(duplicate)
  
}

bday_sim(30)

```


Iterating 10000 times for each group size between 2 and 50. Then, for each group size, computing the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. 

```{r}
sim_res = 
  expand_grid(
    n = c(2:50),
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |> 
  group_by(n) |> 
    summarize(prob = mean(res))
```


Making a plot showing the probability as a function of group size.

```{r}
sim_res |> 
  ggplot(aes(x = n, y = prob )) +
  geom_line()
```

The shape of the function is a sigmoid function. Larger the group size, higher the probability of at least two people in a group sharing a same birthday. 


## Problem 2

For each dataset, save μ^
 and the p-value arising from a test of H:μ=0
 using α=0.05
. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.


Fixing n=30 and σ=5. Setting μ=0. Generating 5000 datasets from the model. 
```{r}
sim_t = function(n = 30, mu = mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
  )
 
  sim_t_results = broom::tidy(t.test(sim_data$x)
    )
}

sim_results_df = 
  expand_grid(
    mu = 0,
    iter = 1:5000
  ) |> 
  mutate(estimate_df = map(mu, ~ sim_t(mu = .x))) |> 
  unnest(estimate_df)

sim_results_df
```


## Problem 3

Creating a `city_state` variable, tidying, and summarizing within cities to obtain the total number of homicides and the number of unsolved homicides. 


```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    outcome = 
      ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), "unsolved", "solved")
    )
```

The dataframe `homicide_df` has `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns representing more than 52000 criminal homicides over the past decade in 50 of the largest American cities, obtained by Washington Post. The data includes the id, date, location of homicide, demographic information about the victim, `city_state` variable that describes city and state, and `outcome` variable describing the  whether an arrest was made.


Obtaining the total number of homicides and the number of unsolved homicides by `city_state`. 

```{r}
homicide_city_df =
homicide_df |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(outcome == "unsolved")
  )
```


For the city of Baltimore, MD, estimating the proportion of homicides that are unsolved; saving the output of prop.test as an R object, applying the broom::tidy to this object and pulling the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
baltimore_prop = 
  prop.test(
    x = filter(homicide_city_df, city_state == "Baltimore, MD") |> 
      pull(unsolved_homicides),
    n = filter(homicide_city_df, city_state == "Baltimore, MD") |> 
      pull(total_homicides)
  )

broom::tidy(baltimore_prop) |> 
  knitr::kable(digits = 4)
```


Using `purrr` package to run prop.test for each of the cities and extracting both the proportion of `unsolved_homicides` and the confidence interval. 

```{r}
homicide_plot = 
homicide_city_df |> 
  mutate(
    props = map2(unsolved_homicides, total_homicides, \(x, y) prop.test(x = x, n = y)),
    tidy_props = map(props, broom::tidy)
  ) |> 
  unnest(tidy_props) |> 
  select(city_state, estimate, conf.low, conf.high)
```


Creating a plot that shows the estimates and CIs for each city, organized according to the proportion of unsolved homicides.

```{r}
homicide_plot |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90))
```

