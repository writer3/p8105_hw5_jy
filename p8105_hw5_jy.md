HW 5
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Load key packages

``` r
library(tidyverse)
library(broom)
set.seed(1000)
```

## Problem 1

Writing a function that for a fixed group size randomly draws
“birthdays” for each person, checks whether there are duplicate
birthdays in the group, and returns TRUE or FALSE based on the result.

``` r
bday_sim = function(n) {
  
  bdays = sample(1:365, size = n, replace = TRUE)
  
  duplicate = length(unique(bdays)) < n #check for any duplicates, and FALSE if <n
  
  return(duplicate)
  
}

bday_sim(30)
```

    ## [1] TRUE

Iterating 10000 times for each group size between 2 and 50. Then, for
each group size, computing the probability that at least two people in
the group will share a birthday by averaging across the 10000 simulation
runs.

``` r
sim_res = 
  expand_grid(
    n = c(2:50),
    iter = 1:10000
  ) |> 
  mutate(res = map_lgl(n, bday_sim)) |>  #mutate, map across n sample size, can use map_lgl here since we know the function would result in TRUE or FALSE
  group_by(n) |> 
    summarize(prob = mean(res))
```

Making a plot showing the probability as a function of group size.

``` r
sim_res |> 
  ggplot(aes(x = n, y = prob )) +
  geom_line()
```

<img src="p8105_hw5_jy_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

The shape of the function is a sigmoid function. Larger the group size,
higher the probability of at least two people in a group sharing a same
birthday.

## Problem 3

Creating a `city_state` variable, tidying, and summarizing within cities
to obtain the total number of homicides and the number of unsolved
homicides.

``` r
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    outcome = 
      ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), "unsolved", "solved")
    )
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (8): uid, victim_last, victim_first, victim_race, victim_sex, city, stat...
    ## dbl (4): reported_date, victim_age, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The dataframe `homicide_df` has 52179 rows and 14 columns representing
more than 52000 criminal homicides over the past decade in 50 of the
largest American cities, obtained by Washington Post. The data includes
the id, date, location of homicide, demographic information about the
victim, `city_state` variable that describes city and state, and
`outcome` variable describing the whether an arrest was made.

Obtaining the total number of homicides and the number of unsolved
homicides by `city_state`.

``` r
homicide_city_df =
homicide_df |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(outcome == "unsolved")
  )
```

For the city of Baltimore, MD, estimating the proportion of homicides
that are unsolved; saving the output of prop.test as an R object,
applying the broom::tidy to this object and pulling the estimated
proportion and confidence intervals from the resulting tidy dataframe.

``` r
baltimore_prop = 
  prop.test(
    x = filter(homicide_city_df, city_state == "Baltimore, MD") |> 
      pull(unsolved_homicides),
    n = filter(homicide_city_df, city_state == "Baltimore, MD") |> 
      pull(total_homicides)
  )

broom::tidy(baltimore_prop) |> 
  knitr::kable(digits = 4)
```

| estimate | statistic | p.value | parameter | conf.low | conf.high | method                                               | alternative |
|---------:|----------:|--------:|----------:|---------:|----------:|:-----------------------------------------------------|:------------|
|   0.6456 |   239.011 |       0 |         1 |   0.6276 |    0.6632 | 1-sample proportions test with continuity correction | two.sided   |
